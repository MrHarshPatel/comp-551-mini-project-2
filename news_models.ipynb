{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.datasets import fetch_20newsgroups \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating test + train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian', \n",
    "              'comp.graphics', 'sci.med']\n",
    "\n",
    "# currently looking at all categories \n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, remove=('headers', 'footers', 'quotes'))\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, remove=('headers', 'footers', 'quotes'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['SVM', 'Logistic Regression', 'AdaBoost', 'Decision Tree', 'Random Forest']\n",
    "\n",
    "# just need to add randomforest \n",
    "models = [\n",
    "    LinearSVC(random_state=0,max_iter=2000),\n",
    "    LogisticRegression(random_state=0,max_iter=1000),\n",
    "    AdaBoostClassifier(n_estimators=50, learning_rate=1,random_state=0),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    RandomForestClassifier(max_depth=2, random_state=0)\n",
    "]\n",
    "\n",
    "parameter_grids = [\n",
    "    [ # Parameter Grid for Linear SVC.\n",
    "#         { # l1 Case: Dual False, Squared_hinge\n",
    "#             'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "#             'tfidf__use_idf': [True, False],\n",
    "#             'clf__loss': ['squared_hinge'],\n",
    "#             'clf__penalty': ['l1'],\n",
    "#             'clf__C': range(1,100,10),\n",
    "#             'clf__tol': [1e-2, 1e-4, 1e-9],\n",
    "#             'clf__dual': [False]\n",
    "#         },\n",
    "#         { # l2 Hinge Case: Dual True\n",
    "#             'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "#             'tfidf__use_idf': [True, False],\n",
    "#             'clf__loss': ['hinge'],\n",
    "#             'clf__penalty': ['l2'],\n",
    "#             'clf__C': range(1,100,10),\n",
    "#             'clf__tol': [1e-2, 1e-4, 1e-9],\n",
    "#             'clf__dual': [True]\n",
    "#         },\n",
    "#         { # l2 Square Hinged Case\n",
    "#             'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "#             'tfidf__use_idf': [True, False],\n",
    "#             'clf__loss': ['squared_hinge'],\n",
    "#             'clf__penalty': ['l2'],\n",
    "#             'clf__C': range(1,100,10),\n",
    "#             'clf__tol': [1e-2, 1e-4, 1e-9],\n",
    "#             'clf__dual': [True,False]\n",
    "#         },\n",
    "        {\n",
    "            'vect__ngram_range': [(1,1), (1,2)],\n",
    "            'tfidf__use_idf': (True, False),\n",
    "            'vect__stop_words': ('english', None)\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "            'tfidf__use_idf': (True, False),\n",
    "            'clf__penalty': ('l2', 'l1')\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "            'tfidf__use_idf': (True, False),\n",
    "            'clf__learning_rate': (1, 2, 0.5),\n",
    "            'clf__n_estimators': (10, 50, 100)\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "            'tfidf__use_idf': (True, False),\n",
    "            'clf__criterion': ('gini', 'entropy'),\n",
    "        },\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "            'tfidf__use_idf': (True, False),\n",
    "            'clf__criterion': ('gini', 'entropy'),\n",
    "        }\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runGridSearchCV(parameter_grids, models, model_names):\n",
    "    start = time.time()\n",
    "    i = 0\n",
    "    best_scores = []\n",
    "    best_params = []\n",
    "    for model in models: \n",
    "        print(\"Currently training model: \", model_names[i])\n",
    "\n",
    "        text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                            ('tfidf', TfidfTransformer()),\n",
    "                            ('clf', model)])\n",
    "\n",
    "        _  = text_clf.fit(twenty_train.data, twenty_train.target)    \n",
    "\n",
    "        gs_clf = GridSearchCV(text_clf, parameter_grids[i], n_jobs=-1, cv=3,error_score=0.0)\n",
    "        gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "        best_scores.append(gs_clf.best_score_)\n",
    "        best_params.append(gs_clf.best_params_)\n",
    "\n",
    "        print(\"Time taken: \", time.time()-start)\n",
    "        print(\"Best score : \", gs_clf.best_score_)\n",
    "        print(\"Best params: \", gs_clf.best_params_)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runRandomizedSearchCV(parameter_grids, models, model_names, num_iters=100):\n",
    "    start = time.time()\n",
    "    i = 0\n",
    "    best_scores = []\n",
    "    best_params = []\n",
    "    for model in models: \n",
    "        print(\"Currently training model: \", model_names[i])\n",
    "\n",
    "        text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                            ('tfidf', TfidfTransformer()),\n",
    "                            ('clf', model)])\n",
    "\n",
    "        _  = text_clf.fit(twenty_train.data, twenty_train.target)    \n",
    "\n",
    "        rs_clf = RandomizedSearchCV(text_clf, parameter_grids[i], n_jobs=-1, cv=3,error_score=0.0,n_iter = num_iters, verbose = 2, random_state=0)\n",
    "        rs_clf = rs_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "        best_scores.append(rs_clf.best_score_)\n",
    "        best_params.append(rs_clf.best_params_)\n",
    "\n",
    "        print(\"Time taken: \", time.time()-start)\n",
    "        print(\"Best score : \", rs_clf.best_score_)\n",
    "        print(\"Best params: \", rs_clf.best_params_)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "runGridSearchCV() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-94141bf6c078>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrunGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameter_grids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: runGridSearchCV() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "runGridSearchCV(parameter_grids, models, model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Hyperparameters For Each Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc_rs = [\n",
    "    {\n",
    "        'vect__ngram_range': [(1,1),(1,2)],\n",
    "        'vect__stop_words': ['english',None],\n",
    "        'tfidf__use_idf': [True,False],\n",
    "        'clf__C': [0.01, 0.05, 0.1, 0.5, 1.0, 10, 20 , 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "        'clf__penalty': ['l2','l1'],\n",
    "        'clf__loss': ['hinge','squared_hinge'],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrowed from randomized search\n",
    "linear_svc_gs = [\n",
    "    {\n",
    "        'vect__ngram_range': [(1,1),(1,2)],\n",
    "        'vect__stop_words': ['english',None],\n",
    "        \n",
    "        'tfidf__use_idf': [True,False],\n",
    "        'clf__C': [75,80,85],\n",
    "        'clf__penalty': ['l2','l1'],\n",
    "        'clf__loss': ['hinge','squared_hinge'],\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runGridSearchCV(linear_svc_gs, [models[0]], [model_names[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently training model:  SVM\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  8.8min\n"
     ]
    }
   ],
   "source": [
    "runRandomizedSearchCV(linear_svc_rs, [models[0]], [model_names[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runGridSearchCV(linear_svc_pg, [models[0]], [model_names[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_gs = [\n",
    "        {\n",
    "            'vect__ngram_range': [(1,1),(1,2)],\n",
    "            'vect__stop_words': ['english'],\n",
    "            'tfidf__use_idf': [True],\n",
    "            'clf__C': [55,60,65],\n",
    "            'clf__penalty': ['l2'],\n",
    "            'clf__solver': ['newton-cg','sag','lbfgs','liblinear','saga'],\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runGridSearchCV(logistic_regression_gs, [models[1]], [model_names[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_rs = [\n",
    "        {\n",
    "            'vect__ngram_range': [(1,1),(1,2)],\n",
    "            'vect__stop_words': ['english',None],\n",
    "            'tfidf__use_idf': [True,False],\n",
    "            'clf__C': [0.01, 0.05, 0.1, 0.5, 1.0, 10, 20 , 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "            'clf__penalty': ['l2','l1','elasticnet'],\n",
    "            'clf__solver': ['newton-cg','sag','lbfgs','liblinear','saga'],\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently training model:  Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed: 26.6min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 180.4min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  10982.911972284317\n",
      "Best score :  0.7578221672264451\n",
      "Best params:  {'vect__stop_words': 'english', 'vect__ngram_range': (1, 2), 'tfidf__use_idf': True, 'clf__solver': 'saga', 'clf__penalty': 'l2', 'clf__C': 60}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runRandomizedSearchCV(logistic_regression_rs, [models[1]], [model_names[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runGridSearchCV(logistic_regression_pg, [models[1]], [model_names[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_rs = [\n",
    "        {\n",
    "            'vect__ngram_range': [(1,1),(1,2)],\n",
    "            'vect__stop_words': ['english',None],\n",
    "            'tfidf__use_idf': [True,False],\n",
    "            'clf__bootstrap': [True,False],\n",
    "            'clf__max_depth' : [10,20,30,40,50,60,70,80,90,100,None],\n",
    "            'clf__n_estimators' : [100, 200, 400, 700, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
    "#             'clf__C': [0.01, 0.05, 0.1, 0.5, 1.0, 10, 20 , 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "            'clf__min_samples_split': [2,5,10],\n",
    "            'clf__max_features': ['auto','sqrt'],\n",
    "#             'clf__penalty': ['l2','l1','elasticnet'],\n",
    "#             'clf__solver': ['newton-cg','sag','lbfgs','liblinear','saga'],\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runRandomizedSearchCV(random_forest_rs, [models[4]], [model_names[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_gs = [\n",
    "        {\n",
    "            'vect__ngram_range': [(1,2)],\n",
    "            'vect__stop_words': ['english'],\n",
    "            'tfidf__use_idf': [True],\n",
    "            'clf__bootstrap': [True,False],\n",
    "            'clf__max_depth' : [20,50,100,None],\n",
    "            'clf__n_estimators' : [600, 700, 800],\n",
    "            'clf__min_samples_split': [2,10],\n",
    "            'clf__max_features': ['auto','sqrt'],\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runGridSearchCV(logistic_regression_pg, [models[4]], [model_names[4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_rs = [\n",
    "        {\n",
    "            'vect__ngram_range': [(1,1),(1,2)],\n",
    "            'vect__stop_words': ['english',None],\n",
    "            'tfidf__use_idf': [True,False],\n",
    "            'clf__max_features': [None,'auto','sqrt','log2'],\n",
    "            'clf__max_depth': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "            'clf__min_impurity_decrease': [0.00005,0.0001,0.0002,0.0005,0.001,0.0015,0.002,0.005,0.01]\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runRandomizedSearchCV(decision_tree_rs, [models[3]], [model_names[3]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
